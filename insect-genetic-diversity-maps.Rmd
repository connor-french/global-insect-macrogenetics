---
title: "Genetic Diversity Maps"
author: "Connor French"
#date: "5/12/2020"
output: 
  html_document:
    code_folding: hide
runtime: shiny

---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


```{r, warning=FALSE, message=FALSE}
library(here)
library(sf)
library(rnaturalearth)
library(plotly)
library(cowplot)
library(wesanderson)
library(raster)
library(tidyverse)
library(broom)
library(gt)
library(shiny)
```



Read in summary stats files
```{r warning=FALSE, message=FALSE}
spread_path <- here("output", "spreadsheets")

# rescale avg pi to 0-1
rescale <- function(x) {
  y <- (x - min(x)) / (max(x) - min(x))
  return(y)
}

sumstats <- read_csv(here(spread_path, "med_3_10_sumstats.csv")) %>% 
  mutate(log_num_otu = log10(num_otu),
         log_num_ind = log10(num_ind),
         scaled_pi = rescale(avg_pi),
         gen_health = scaled_pi * hill_1) %>% 
  filter(avg_pi < 0.02) # outlier cell

```

Read in and filter environmental variables. Keeping it small for exploratory purposes right now. Once we decide on what explanatory variables to use, I'll move this to a separate script so this document doesn't have to work so hard.
```{r, cache=TRUE}
explanatory_path <- here("data", "climate_agg")

explanatory_files <- list.files(explanatory_path, pattern = "*medium*", full.names = TRUE)

explanatory_rasters <- stack(explanatory_files)

names(explanatory_rasters) <- str_remove(basename(explanatory_files), ".tif")
```

```{r}
explanatory <- explanatory_rasters[sumstats$cell] 
names(explanatory) <- names(explanatory_rasters)

explanatory <- as_tibble(explanatory) %>% 
  bind_cols(sumstats[,c("log_num_otu", "log_num_ind", "num_order")]) %>% 
  mutate(soil_medium_hwsd = as.factor(soil_medium_hwsd))

explanatory_vars <- colnames(explanatory)
```



Read in rasters at the two resolutions to provide a template for the genetic diversity maps. Also obtaining the basemap, setting the color palette for the maps, and filtering the summary statistics.  
```{r}
template_medium <- raster(here("data", "templates", "template_medium.tif"))

world_basemap <-
  ne_coastline(scale = "small", returnclass = "sf") %>%
  st_transform(crs(template_medium)) %>% 
  st_simplify()

pal <- wes_palette("Zissou1", 100, type = "continuous")

sumstats_names <- colnames(sumstats %>%
                        select(-cell)) %>%
  set_names()
```


Function to create an sf polygon from the summary statistic data.
```{r}
create_poly <- function(resolution){
  rast <- raster(get(paste0("template_", resolution)))
  
  sumstats <- get("sumstats")
  
  explanatory <- get("explanatory")
  
  all_df <- bind_cols(sumstats, explanatory %>% select(-num_order, -log_num_ind, -log_num_otu)) %>% 
    arrange(cell)
  
  rast[all_df$cell] <- all_df$avg_pi
  
  rast_poly <- rasterToPolygons(rast) %>% 
    st_as_sf() %>%
    bind_cols(all_df)
  # %>% 
  #   select(-layer, -log_num_otu1, -log_num_ind1, -num_order1) 

  return(rast_poly)
}

```

Function to create legends for maps. Necessarily hack-y because plotly has trouble plotting a legend when both my layers are in the Behrmann equal area projection. geom_sf does an under-the-hood transformation of the summary statistic polygon to WGS84 lat-longs and just rescales the axes to maintain the projection, but keeps the world basemap the same for some reason. This results in different numbers for the graticules. ggplot plots the map + legend fine, but when plotly wants to plot the legend, it needs to refer to the tick values, and a subsetting error occurs. I assume it's because one layer is scaled -180 to 180, but the other is ~2e7 to ~2e7. I'm writing the legend for each plot to an image file, then reading in the image and using plotly's layout() function to plot. All of the other interactive mapping solutions (leaflet, tmap, mapdeck) don't like a World Behrmann Equal Area projection, so I'm forced into this situation. 
```{r}
write_legends <- function(sumstat, resolution) {
  filename <-
    here("output",
         "legends",
         paste0(sumstat, "_", resolution, ".png"))
  
  if (!file.exists(filename)) {
    sumstat_poly <- create_poly(resolution)

    sumstat_leg <- ggplot() +
      geom_sf(data = sumstat_poly, aes_string(fill = sumstat, size = 0.1)) +
      scale_fill_gradientn(colors = pal, name = sumstat) +
      theme(legend.background = element_rect(fill = alpha("white", 0.5)))
    
    sumstat_leg <- sumstat_leg %>%
      cowplot::get_legend()
    
    
    ggsave(
      sumstat_leg,
      filename = filename,
      width = 2,
      height = 3,
      bg = "transparent"
    )
  }
  
  
}
```

Write legends to file for plotting and create a list of sumstat polygons for each resolution.
```{r, results='hide'}
resolutions <- "medium"
# 
# sumstat_poly <- vector(mode = "list", length = 1)
# 
# names(sumstat_poly) <- c("medium")
# 
# for (res in seq_along(resolutions)) {
#   map(sumstats, ~write_legends(.x, resolution = resolutions[res]))
#   sumstat_poly[[res]] <- create_poly(resolutions[res])
#}

map(names(sumstats), ~write_legends(.x, resolution = "medium"))
sumstat_poly <- create_poly("medium") 
```


Bioclim variables for reference:  
![](https://www.researchgate.net/profile/Eric_Salas/publication/319434027/figure/tbl1/AS:668534812180503@1536402528990/List-of-19-bioclimatic-variables-used-in-bioclimatic-envelope-model-development-Names.png)   

# Genetic Diversity Map {.tabset}
## Genetic summary stat
```{r, warning=FALSE, message=FALSE, echo=FALSE}
inputPanel(
  selectInput("sumstat", "Summary Statistic",
                  choices = sumstats_names),
  
  numericInput("min_otu", "Minimum number of OTUs",
                  min = 10, 
                  max = 200,
                  step = 10,
                  value = 10),
  
  selectInput("explanatory", "Explanatory Variable", 
                choices = explanatory_vars)
)
```

```{r, reactive-pre-processing}
# filter per input
df_filt <- reactive({
      all_df %>% 
        filter(num_otu >= input$min_otu)
    })

# filter polygon of sumstats
ss_poly_filt <- reactive({
      sumstat_poly %>% 
        filter(num_otu >= input$min_otu)
    })


# make a quick linear model of sumstats
ss_lm <- reactive({
      lm(reformulate(input$explanatory, input$sumstat), data = ss_poly_filt())
    })

# linear model of min otu = 10
ss_lm_10 <- reactive({
      lm(reformulate(input$explanatory, input$sumstat), data = sumstat_poly)
    })
# plot the explanatory raster
exp_rast <- reactive({
      raster::subset(explanatory_rasters, input$explanatory)
    })

# basemap I'm using in a couple plots
basemap <- reactive({
      ggplot() +
        geom_sf(data = world_basemap,
                fill = "transparent",
                show.legend = FALSE)
    })
```


```{r, sumstat_plot}
renderPlotly({
      ggplotly(
        basemap() +
          geom_sf(
            data = sumstat_poly,
            fill = "lightgray",
            color = "gray"
          ) +
          geom_sf(
            data = ss_poly_filt(),
            aes_string(fill = input$sumstat),
            size = 0.1
          ) +
          scale_fill_gradientn(colors = pal, guide = NULL) +
          labs(title = paste0("Map of ", input$sumstat, ". # cells = ", nrow(ss_poly_filt())), ". Gray cells are those when Min OTU = 10.") +
          ggthemes::theme_map()
      ) %>%
        layout(
          images = list(
            source = base64enc::dataURI(file = here(
              "output", "legends", paste0(input$sumstat, "_", "medium", ".png"))
            ),
            x = 0,
            y = 0,
            sizex = 0.75,
            sizey = 0.75,
            xref = "paper",
            yref = "paper",
            xanchor = "left",
            yanchor = "bottom"
          ),
          margin = list(t = 50)
        )
    })
    
```

```{r}
renderPlot({
  ggplot() +
    geom_density(data = sumstat_poly, aes_string(x = input$sumstat)) +
    geom_density(data = ss_poly_filt(), aes_string(x = input$sumstat), color = "green") +
    labs(title = paste0("Black is Min OTU = 10, Green is Min OTU = ", nrow(ss_poly_filt()))) +
    theme_minimal()
})
```

## Explanatory variable

```{r, explanatory-raster}
renderPlot({
      plot(exp_rast())
    })
```

```{r, extracted-explanatory-map}
renderPlot({
      ggplot() +
          geom_sf(data = world_basemap,
                fill = "transparent",
                show.legend = FALSE) +
          geom_sf(
            data = ss_poly_filt(),
            aes_string(fill = input$explanatory),
            size = 0.1
          ) +
          scale_fill_gradientn(colors = pal) +
          labs(title = paste0("Map of ", input$explanatory)) +
          ggthemes::theme_map()
    })
```

## Relationships
```{r, scatterplot}
renderPlot({
      ggplot() +
        geom_point(data = sumstat_poly, 
                   aes_string(x = input$explanatory, y = input$sumstat), 
                   color = "lightgray") +
        geom_point(data = ss_poly_filt(), 
                   aes_string(x = input$explanatory, y = input$sumstat)) +
        geom_smooth(data = sumstat_poly, 
                   aes_string(x = input$explanatory, y = input$sumstat),
                   method = "lm",
                   color = "gray") +
        geom_smooth(data = ss_poly_filt(), 
                   aes_string(x = input$explanatory, y = input$sumstat),
                   method = "lm",
                   color = "black") +
        labs(title = "Light gray points are those when Min OTU = 10") +
        theme_minimal()
    })
```

```{r}
render_gt({
      
      lm_tidy_10 <- ss_lm_10() %>% 
        tidy() %>% 
        slice(-1) %>% 
        select(estimate, p.value)
      
      lm_glance_10 <- ss_lm_10() %>% 
        glance() %>% 
        select(r.squared)
      
      bind_cols(lm_tidy_10, lm_glance_10) %>% 
        gt() %>% 
        fmt_number(everything(), decimals = 3) %>% 
        tab_header(
          title = "Min OTU = 10 LM"
          )
    })


render_gt({
      
      lm_tidy <- ss_lm() %>% 
        tidy() %>% 
        slice(-1) %>% 
        select(estimate, p.value)
      
      lm_glance <- ss_lm() %>% 
        glance() %>% 
        select(r.squared)
      
      bind_cols(lm_tidy, lm_glance) %>% 
        gt() %>% 
        fmt_number(everything(), decimals = 3) %>% 
        tab_header(
          title = "Filtered LM"
          )
    })
```

<br>
<br>
<br>
<br>
<br>




# To-Do
Re-do alignment format to make exploration easier:  
* only initially filter for OTUs with > 1 sequence (and the invasive species filtering, etc.)
* align all sequences for each OTU
* calculate pairwise differences for all combinations of within-otu sequences
* use this as a master data set, where I filter the metadata for each filtering regime and calculate the summary statistics based on subsets of this master data set. That way, I'm not duplicating alignment effort and I can explore a wider variety of filtering strategies.

Resampling environment:  
* resample to closest equal-area grid size, then aggregate using the mean, mode, whatever

Figure out what to do with outlier pi values.  
* After some investigation, the pi > 0.02 cells in West Africa don't seem to have any noticable problems. 
* The sequence lengths for each bin are reasonable (~700 bp) 
* There aren't any bins with excessive proportions of gaps (~4% at most)
* There aren't excessively high pi values driving the distributions (mostly range from 0.01-0.05)

How do I visualize these in a reasonable fashion, then?

Think of how to summarize diversity by Wallacean Realms.

